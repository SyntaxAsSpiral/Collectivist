# Collectivist LLM Configuration
# Copy this file to .env and uncomment/modify the settings you need

# =============================================================================
# LLM PROVIDER SELECTION
# Choose one: lmstudio, ollama, openrouter, openai, anthropic, pollinations
# =============================================================================

#COLLECTIVIST_LLM_PROVIDER=lmstudio

# =============================================================================
# MODEL SELECTION (Optional - uses smart defaults if not specified)
# Uncomment and set to your preferred model within the chosen provider
# =============================================================================

#COLLECTIVIST_LLM_MODEL=llama3.1-8b-instruct

# =============================================================================
# API KEYS (Required for cloud providers)
# =============================================================================

# For OpenRouter
#COLLECTIVIST_LLM_API_KEY=sk-or-v1-your-openrouter-key

# For OpenAI
#COLLECTIVIST_LLM_API_KEY=sk-your-openai-key

# For Anthropic
#COLLECTIVIST_LLM_API_KEY=sk-ant-your-anthropic-key

# =============================================================================
# CUSTOM ENDPOINTS (Optional - overrides default provider URLs)
# =============================================================================

#COLLECTIVIST_LLM_BASE_URL=https://custom-endpoint.com/v1

# =============================================================================
# CONFIGURATION EXAMPLES BY PROVIDER
# =============================================================================

# -----------------------------------------------------------------------------
# LMSTUDIO (Local, Recommended - No API Key Needed)
# Install LMStudio, load a model, and start the local server
# -----------------------------------------------------------------------------
#COLLECTIVIST_LLM_PROVIDER=lmstudio
#COLLECTIVIST_LLM_MODEL=llama-3.1-8b-instruct-q4_0  # Whatever you have loaded

# -----------------------------------------------------------------------------
# OLLAMA (Local - No API Key Needed)
# Install Ollama, pull models with 'ollama pull <model>'
# -----------------------------------------------------------------------------
#COLLECTIVIST_LLM_PROVIDER=ollama
#COLLECTIVIST_LLM_MODEL=llama3.1:8b-instruct-q4_0  # Exact model name

# -----------------------------------------------------------------------------
# OPENROUTER (Cloud - API Key Required)
# Access to 100+ models through unified API
# -----------------------------------------------------------------------------
#COLLECTIVIST_LLM_PROVIDER=openrouter
#COLLECTIVIST_LLM_API_KEY=sk-or-v1-...
#COLLECTIVIST_LLM_MODEL=meta-llama/llama-3.1-8b-instruct  # Provider/model format
#COLLECTIVIST_LLM_MODEL=anthropic/claude-3-haiku
#COLLECTIVIST_LLM_MODEL=openai/gpt-4o-mini

# -----------------------------------------------------------------------------
# OPENAI (Cloud - API Key Required)
# Direct access to OpenAI models
# -----------------------------------------------------------------------------
#COLLECTIVIST_LLM_PROVIDER=openai
#COLLECTIVIST_LLM_API_KEY=sk-...
#COLLECTIVIST_LLM_MODEL=gpt-4o-mini     # Cost-effective default
#COLLECTIVIST_LLM_MODEL=gpt-4-turbo     # Most capable
#COLLECTIVIST_LLM_MODEL=gpt-4o          # Latest GPT-4 Optimized

# -----------------------------------------------------------------------------
# ANTHROPIC (Cloud - API Key Required)
# Claude models through official API
# -----------------------------------------------------------------------------
#COLLECTIVIST_LLM_PROVIDER=anthropic
#COLLECTIVIST_LLM_API_KEY=sk-ant-...
#COLLECTIVIST_LLM_MODEL=claude-3-haiku-20240307     # Fast & cheap
#COLLECTIVIST_LLM_MODEL=claude-3-sonnet-20240229    # Best quality
#COLLECTIVIST_LLM_MODEL=claude-3-opus-20240229      # Most capable

# -----------------------------------------------------------------------------
# POLLINATIONS (Specialized - No API Key)
# Image generation focused, experimental
# -----------------------------------------------------------------------------
#COLLECTIVIST_LLM_PROVIDER=pollinations
#COLLECTIVIST_LLM_MODEL=openai  # or anthropic

# =============================================================================
# SMART DEFAULTS (Used when LLM_MODEL is not specified)
# =============================================================================
#
# LMStudio: local-model (whatever is loaded in LMStudio)
# Ollama: llama3.1 (modern, capable model)
# OpenRouter: meta-llama/llama-3.1-8b-instruct (good balance)
# OpenAI: gpt-4o-mini (cost-effective default)
# Anthropic: claude-3-haiku-20240307 (fast & reliable)
# Pollination: openai

# =============================================================================
# TESTING YOUR CONFIGURATION
# =============================================================================
#
# Test your LLM connection:
# python -c "from templates.collection-minimal.llm import LLMClient; print('✅ Connected!' if LLMClient.from_env().test_connection() else '❌ Failed to connect')"
#
# List available models (if supported by provider):
# python -c "from templates.collection-minimal.llm import LLMClient; print(LLMClient.from_env().get_available_models())"
